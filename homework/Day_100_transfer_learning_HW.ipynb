{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python [conda env:ndp]","language":"python","name":"conda-env-ndp-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.5"},"colab":{"name":"Day_100_transfer_learning_HW.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jDgW0Jtb0K-3","colab_type":"text"},"source":["## 作業\n","礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n","\n","\n","最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n","\n","另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"]},{"cell_type":"code","metadata":{"id":"sLgK_6gtGQPk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WVTc6Ii-I1tb","colab_type":"text"},"source":["### 參考\n","https://www.kaggle.com/kgkevinwg/monkey-classifier-97-accuracy-using-resnet-50/notebook\n","\n","https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/\n","\n","https://www.kaggle.com/kgkevinwg/monkey-classifier-97-accuracy-using-resnet-50/notebook"]},{"cell_type":"code","metadata":{"id":"-Un5Q4Wx0K-5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"46e15c67-4234-46ea-ba68-11c668b461d6","executionInfo":{"status":"ok","timestamp":1565099222517,"user_tz":-480,"elapsed":2632,"user":{"displayName":"陳瑄","photoUrl":"https://lh6.googleusercontent.com/-iKdeQLX63W4/AAAAAAAAAAI/AAAAAAAAABM/cRIA--JsNdw/s64/photo.jpg","userId":"18359763489271700141"}}},"source":["from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","%matplotlib inline\n","import keras\n","from keras.applications import VGG16 \n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.optimizers import Adam\n","from keras.applications.resnet50 import ResNet50\n","# from keras.models import Model\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"LNBSS6HS8l6v","colab_type":"code","colab":{}},"source":["batch_size = 64 # batch 的大小，如果出現 OOM error，請降低這個值\n","num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n","epochs = 30 # 訓練的 epochs 數量"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t4P2CjDo3mxD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"outputId":"5e332fff-02c6-4eb8-e1c0-bb9e23c7edce","executionInfo":{"status":"ok","timestamp":1565099231129,"user_tz":-480,"elapsed":11211,"user":{"displayName":"陳瑄","photoUrl":"https://lh6.googleusercontent.com/-iKdeQLX63W4/AAAAAAAAAAI/AAAAAAAAABM/cRIA--JsNdw/s64/photo.jpg","userId":"18359763489271700141"}}},"source":["# 讀取 Cifar-10 資料集\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","input_shape = x_train.shape[1:]\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","y_train = to_categorical(y_train, num_classes)\n","y_test = to_categorical(y_test, num_classes)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 6s 0us/step\n","x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"30dTJtz70SEg","colab_type":"code","colab":{}},"source":["# 建立 ImageDataGenerator，並指定我們要做資料增強的數值範圍\n","# rescale 將 image 做標準化\n","data_generator = ImageDataGenerator(\n","    rotation_range=20, # 旋轉\n","    width_shift_range=0.2, # 平移\n","    height_shift_range=0.2,\n","    horizontal_flip=True,\n","    rescale= 1./255)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3wz31BPYLWwk","colab_type":"code","colab":{}},"source":["test_generator = ImageDataGenerator(rescale = 1./255)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D8kYre1wD9V8","colab_type":"code","colab":{}},"source":["data_generator.fit(x_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G04JMFyo4l3K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":360},"outputId":"5eed2833-63b8-4115-e280-9c29c9d68f55","executionInfo":{"status":"ok","timestamp":1565099258302,"user_tz":-480,"elapsed":18197,"user":{"displayName":"陳瑄","photoUrl":"https://lh6.googleusercontent.com/-iKdeQLX63W4/AAAAAAAAAAI/AAAAAAAAABM/cRIA--JsNdw/s64/photo.jpg","userId":"18359763489271700141"}}},"source":["'''\n","ResNet50 代表我們使用從 imagenet 訓練好的參數來初始\n","pooling avg 把 feature maps 變成⼀維的向量\n","include_top 將原本的 Dense layer 拔掉，因為原本這個網路是用來做 1000 個分類的模型，我們必須替換成⾃己的 Dense layer 來符合我們⾃己資料集的類別數量\n","'''\n","# 建立 ResNet50 模型\n","resnet_model = ResNet50(input_shape=input_shape,\n","                        weights='imagenet',\n","                        include_top=False)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0806 13:47:20.124352 140391513520000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0806 13:47:20.163645 140391513520000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0806 13:47:20.174381 140391513520000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n","\n","W0806 13:47:20.218638 140391513520000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","W0806 13:47:20.219787 140391513520000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","W0806 13:47:23.129492 140391513520000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","W0806 13:47:23.221044 140391513520000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n","  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94658560/94653016 [==============================] - 4s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WfCXbmC5EzON","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"1341da97-35ba-4199-e945-4de7fd3c1f35","executionInfo":{"status":"ok","timestamp":1565097506926,"user_tz":-480,"elapsed":9965,"user":{"displayName":"陳瑄","photoUrl":"https://lh6.googleusercontent.com/-iKdeQLX63W4/AAAAAAAAAAI/AAAAAAAAABM/cRIA--JsNdw/s64/photo.jpg","userId":"18359763489271700141"}}},"source":["# # 建立VGG16模型\n","# conv_vgg = VGG16(weights = 'imagenet',\n","#                  include_top = False,\n","#                  input_shape = input_shape)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 2s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZrSpS6P6E6o8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":340},"outputId":"e817da58-181b-4be3-c1b4-b59335020bbc","executionInfo":{"status":"ok","timestamp":1565099264220,"user_tz":-480,"elapsed":5893,"user":{"displayName":"陳瑄","photoUrl":"https://lh6.googleusercontent.com/-iKdeQLX63W4/AAAAAAAAAAI/AAAAAAAAABM/cRIA--JsNdw/s64/photo.jpg","userId":"18359763489271700141"}}},"source":["model = Sequential()\n","model.add(resnet_model)\n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation('relu'))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","model.summary()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","resnet50 (Model)             (None, 1, 1, 2048)        23587712  \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 2048)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 256)               524544    \n","_________________________________________________________________\n","activation_50 (Activation)   (None, 256)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                2570      \n","_________________________________________________________________\n","activation_51 (Activation)   (None, 10)                0         \n","=================================================================\n","Total params: 24,114,826\n","Trainable params: 24,061,706\n","Non-trainable params: 53,120\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g_ezbP-6-WGb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"74cc0fcc-ae5b-467c-d0bc-ac294216868f","executionInfo":{"status":"ok","timestamp":1565105284868,"user_tz":-480,"elapsed":904774,"user":{"displayName":"陳瑄","photoUrl":"https://lh6.googleusercontent.com/-iKdeQLX63W4/AAAAAAAAAAI/AAAAAAAAABM/cRIA--JsNdw/s64/photo.jpg","userId":"18359763489271700141"}}},"source":["\n","'''\n","已經設定成沒有 Dense layers，且最後⼀層做 GAP\n","使⽤resnet_model.output 可以取出最後一層的 featuremaps\n","使⽤ Flatten 攤平後，再接上 Dense layer，神經元數量與資料集的類別數量⼀致\n","建立模型可以得到一個新的 ResNet-50 模型，且參數是根據 ImageNet 資料集預訓練好的\n","'''\n","# last_map = resnet_model.output\n","# # flatten_map = Flatten()(last_map)\n","# output = Dense(num_classes)(last_map)\n","\n","# model = Model(inputs=resnet_model.input, outputs=output)\n","\n","model.compile(optimizer=Adam(),\n","                  loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","model.fit_generator(data_generator.flow(x_train, y_train, batch_size=batch_size),\n","                        epochs=epochs,\n","                        validation_data=test_generator.flow(x_test, y_test, batch_size=batch_size),\n","                        steps_per_epoch=int(len(x_train)//batch_size),\n","                        validation_steps = 50,\n","                        workers=4)\n","\n","# score = model.evaluate(x_test, y_test, verbose=0)\n","# print('Test loss:', score[0])\n","# print('Test accuracy:', score[1])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","781/781 [==============================] - 219s 281ms/step - loss: 1.4943 - acc: 0.4856 - val_loss: 1.7344 - val_acc: 0.5100\n","Epoch 2/30\n","781/781 [==============================] - 199s 254ms/step - loss: 1.1183 - acc: 0.6177 - val_loss: 1.5452 - val_acc: 0.5819\n","Epoch 3/30\n","781/781 [==============================] - 197s 253ms/step - loss: 1.1441 - acc: 0.6076 - val_loss: 3.5721 - val_acc: 0.4191\n","Epoch 4/30\n","781/781 [==============================] - 198s 253ms/step - loss: 0.9942 - acc: 0.6608 - val_loss: 1.1104 - val_acc: 0.6412\n","Epoch 5/30\n","781/781 [==============================] - 197s 252ms/step - loss: 0.9427 - acc: 0.6796 - val_loss: 0.9259 - val_acc: 0.6859\n","Epoch 6/30\n","781/781 [==============================] - 200s 255ms/step - loss: 0.8598 - acc: 0.7069 - val_loss: 1.3389 - val_acc: 0.6031\n","Epoch 7/30\n","781/781 [==============================] - 195s 249ms/step - loss: 0.8431 - acc: 0.7158 - val_loss: 0.9568 - val_acc: 0.6859\n","Epoch 8/30\n","781/781 [==============================] - 194s 249ms/step - loss: 0.9417 - acc: 0.6821 - val_loss: 1.9495 - val_acc: 0.3669\n","Epoch 9/30\n","781/781 [==============================] - 197s 253ms/step - loss: 0.9350 - acc: 0.6798 - val_loss: 0.8617 - val_acc: 0.7200\n","Epoch 10/30\n","781/781 [==============================] - 196s 251ms/step - loss: 0.7884 - acc: 0.7325 - val_loss: 1.0324 - val_acc: 0.6862\n","Epoch 11/30\n","781/781 [==============================] - 198s 253ms/step - loss: 0.7363 - acc: 0.7506 - val_loss: 1.7647 - val_acc: 0.5603\n","Epoch 12/30\n","781/781 [==============================] - 197s 252ms/step - loss: 0.7523 - acc: 0.7442 - val_loss: 1.0668 - val_acc: 0.6528\n","Epoch 13/30\n","781/781 [==============================] - 198s 253ms/step - loss: 0.6834 - acc: 0.7682 - val_loss: 0.9821 - val_acc: 0.6935\n","Epoch 14/30\n","781/781 [==============================] - 198s 254ms/step - loss: 0.7829 - acc: 0.7344 - val_loss: 0.9422 - val_acc: 0.7019\n","Epoch 15/30\n","781/781 [==============================] - 197s 253ms/step - loss: 0.7595 - acc: 0.7435 - val_loss: 1.0277 - val_acc: 0.6637\n","Epoch 16/30\n","781/781 [==============================] - 198s 254ms/step - loss: 0.7981 - acc: 0.7312 - val_loss: 0.8757 - val_acc: 0.7132\n","Epoch 17/30\n","781/781 [==============================] - 198s 253ms/step - loss: 0.7100 - acc: 0.7577 - val_loss: 0.7916 - val_acc: 0.7512\n","Epoch 18/30\n","781/781 [==============================] - 198s 254ms/step - loss: 0.6493 - acc: 0.7811 - val_loss: 0.8160 - val_acc: 0.7372\n","Epoch 19/30\n","781/781 [==============================] - 200s 256ms/step - loss: 0.6784 - acc: 0.7697 - val_loss: 0.8027 - val_acc: 0.7316\n","Epoch 20/30\n","781/781 [==============================] - 198s 254ms/step - loss: 0.6574 - acc: 0.7800 - val_loss: 0.5845 - val_acc: 0.8106\n","Epoch 21/30\n","781/781 [==============================] - 198s 254ms/step - loss: 0.6672 - acc: 0.7737 - val_loss: 0.6911 - val_acc: 0.7712\n","Epoch 22/30\n","781/781 [==============================] - 196s 252ms/step - loss: 0.5961 - acc: 0.7962 - val_loss: 0.7275 - val_acc: 0.7725\n","Epoch 23/30\n","781/781 [==============================] - 197s 252ms/step - loss: 0.6596 - acc: 0.7771 - val_loss: 0.8947 - val_acc: 0.7119\n","Epoch 24/30\n","781/781 [==============================] - 196s 251ms/step - loss: 0.5795 - acc: 0.8012 - val_loss: 0.7105 - val_acc: 0.7688\n","Epoch 25/30\n","781/781 [==============================] - 197s 252ms/step - loss: 0.5905 - acc: 0.7989 - val_loss: 1.1839 - val_acc: 0.6469\n","Epoch 26/30\n","781/781 [==============================] - 199s 255ms/step - loss: 0.6377 - acc: 0.7836 - val_loss: 0.6158 - val_acc: 0.7944\n","Epoch 27/30\n","781/781 [==============================] - 198s 254ms/step - loss: 0.6607 - acc: 0.7781 - val_loss: 0.8638 - val_acc: 0.7319\n","Epoch 28/30\n","781/781 [==============================] - 199s 255ms/step - loss: 0.5608 - acc: 0.8076 - val_loss: 0.8262 - val_acc: 0.7275\n","Epoch 29/30\n","781/781 [==============================] - 199s 255ms/step - loss: 0.5329 - acc: 0.8176 - val_loss: 0.6930 - val_acc: 0.7602\n","Epoch 30/30\n","781/781 [==============================] - 199s 255ms/step - loss: 0.5112 - acc: 0.8258 - val_loss: 0.8806 - val_acc: 0.7225\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7faed07bf940>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"TUx9SGZ9fVlA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"8058ed51-6f0c-4bd8-8ef0-a7e911b0a03c","executionInfo":{"status":"ok","timestamp":1565105375266,"user_tz":-480,"elapsed":11866,"user":{"displayName":"陳瑄","photoUrl":"https://lh6.googleusercontent.com/-iKdeQLX63W4/AAAAAAAAAAI/AAAAAAAAABM/cRIA--JsNdw/s64/photo.jpg","userId":"18359763489271700141"}}},"source":["score = model.evaluate(x_test/255, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Test loss: 0.898408769416809\n","Test accuracy: 0.7158\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k6O87adZfWoj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}